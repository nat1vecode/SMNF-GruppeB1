---
title: "(Platzhalter)"
author: 
  - Fynn Luyken
  - Jorin Bahns
  - David Piekarski
  - Johannes Rehrl
  - Nathaniel Roumiantsev
date: today
format:
  html:
    toc: true
    number-sections: false
  pdf:
    papersize: a4
    fontsize: 12pt
    toc: true
    number-sections: false
    citation-location: none
bibliography: Literatur.bib
csl: apa.csl

output-file: abstract
---

**GitHub Repository** https://github.com/nat1vecode/SMNF-GruppeB1

**Für die Abgabe aktueller GitHub Hash:** d6e2c29a71247f6ee7e616d8b4aac12ece237290

## Code of Conduct

Im Rahmen dieser wissenschaftlichen Arbeit verpflichten sich alle beteiligten Personen zur Einhaltung folgender Verhaltensgrundsätze:

**Wissenschaftliche Integrität**

Alle Forschenden verpflichten sich zur Einhaltung guter wissenschaftlicher Praxis, insbesondere zur Ehrlichkeit in der Darstellung von Daten, Ergebnissen und Methoden. Plagiate, Datenfälschung und -manipulation werden strikt abgelehnt.

**Respektvolle Zusammenarbeit**

Die Zusammenarbeit im Team basiert auf gegenseitigem Respekt, Fairness und Gleichberechtigung. Diskriminierung, Belästigung oder andere Formen unangemessenen Verhaltens werden nicht toleriert. Vereinbarte und verpflichtende Termine werden zuverlässig eingehalten oder frühzeitig und begründet kommuniziert.

**Faire Aufteilung der Arbeitslast**

Jegliche Arbeit wird gleichmäßig auf alle Gruppenmitglieder aufgeteilt. Sollte sich jemand benachteiligt fühlen, kann dieser dies jederzeit kommunizieren und wird entsprechend berücksichtigt.

**Vermeidung von Interessenkonflikten & Berücksichtigung von Feedback**

Potenzielle Interessenkonflikte werden frühzeitig offengelegt und transparent kommuniziert, um die Unabhängigkeit und Objektivität der Forschung zu gewährleisten. Konstruktives Feedback wird jederzeit mit Wertschätzung aufgenommen, geprüft und entsprechend umgesetzt.

**Vertraulichkeit**

Vertrauliche Informationen, insbesondere personenbezogene Daten oder nicht veröffentlichte Forschungsergebnisse, werden mit der gebotenen Sorgfalt behandelt. Weiterhin verpflichten sich alle Gruppenmitglieder dazu, sämtliche im Zuge des Moduls SMNF (PY1802) erhobenen vertraulichen Daten nicht außerhalb des Moduls zu verbreiten.

**Umgang mit Künstlicher Intelligenz (KI)**

Künstliche Intelligenz darf zur Unterstützung bei Recherche, Analyse oder Textentwurf eingesetzt werden, muss jedoch in angemessener Form kenntlich gemacht werden. KI-Tools werden nicht als Quelle zitiert oder verwendet, sondern dienen ausschließlich der Hilfestellung im Arbeitsprozess.

## 1. Einleitung

Hallo!

## 2. Literaturübersicht

Des Weiteren erkennt das Paper "Cognitive AI for Mitigation of Misinformation in Online Social Networks" [@indu2022] die Relevanz menschlicher Kognitionspsychologie für die Analyse von (Mis-)Informationen, und fokussiert sich auf die Kombination dessen mit Künstlicher Intelligenz. Dabei wird darauf abgezielt, den Menschen bei der Beurteilung von Informationen in den sozialen Netzwerken zu unterstützen.

Das Paper „Zero-trust management using AI: Untrusting the trusted accounts in social media?“ [@fottouh2023] hebt hervor, dass das bloße Vertrauen in verifizierte Accounts nicht ausreicht, um die Qualität und Vertrauenswürdigkeit von Informationen auf Social Media sicherzustellen. Die Autoren regen dazu an, über die reine Identifikation von Fake-Accounts hinauszugehen und auch die Inhalte verifizierter Accounts zu analysieren. Im Hinblick auf unsere Forschungsfrage beschäftigt sich diese Arbeit mit der Notwendigkeit einer KI, welche nicht nur visuelle Merkmale (wie Verifizierung) berücksichtigt, sondern auch Informationen inhaltlich auf ihre Vertrauenswürdigkeit bewertet.

Das Paper „Using a Chatbot to Combat Misinformation: Exploring Gratifications, Chatbot Satisfaction and Engagement, and Relationship Quality Using a Chatbot to Combat Misinformation: Exploring Gratifications, Chatbot Satisfaction and Engagement, and Relationship Quality“ [@cheng2024] untersucht auf Basis der Uses-and-Gratifications-Theorie, die Nutzung des von der Weltgesundheitsorganisation (WHO) entwickelten Chatbots „Florence“, welcher entwickelt wurde um Informationen zu COVID-19 zu verbreiten. Bei einer Umfrage mit 591 Teilnehmern konnten Erkenntnisse gesammelt werden, das unter anderem technische Modernität (Modality), persönliche Unterstützung (Agency), Interaktivität (Interaction) und einfache Navigation (Navigability) die Nutzerzufriedenheit positiv beeinflussen. Im Gegenzug hemmen durch den Nutzer wahrgenommene Datenschutzrisiken die Zufriedenheit. Die Studie liefert dahingehend wertvolle Implikationen für die Gestaltung eines Chatbots, zur Bekämpfung von Fehlinformationen auf Sozialen Netzwerken.

Abschließend zeigt die Studie „Exploring the Use of Personalized AI for Identifying Misinformation on Social Media“ [@jahanbakhsh2023], wie personalisierte KI-Systeme die individuellen Einschätzungen der Nutzenden lernen und darauf basierend weitere Inhalte vorbewerten können. Interessant ist dabei die Erkenntnis, dass solche Systeme die Nutzermeinung beeinflussen können – besonders dann, wenn keine Begründung für die KI-Vorhersage gegeben wird. Das zeigt vor allem, dass KI ein zentrales Nutzendenbedürfnis darstellt: Nur wenn die Funktionsweise nachvollziehbar bleibt, kann eine nachhaltige Vertrauensbeziehung zwischen Nutzenden und System entstehen.

## 3. Methode

### Qualitative Methode

Unser Forschungsprojekt behandelt ein komplexes Themengebiet, das vor allem eine große soziale Komponente beeinhaltet. Mithilfe der qualitativen Methode können wir herausfinden, welche Erfahrungen Menschen mit KI gemacht haben und wie sie darüber denken. Insbesondere für die Nutzendenanforderungen ist es hilfreich, konkrete Vorstellungen zur Umsetzung einer KI zur Detektion von Misinformationen genannt zu bekommen.

Ergänzend hierzu bietet es sich nun an, quantitative Ansätze zur weiteren Forschung zu verwenden, die auf den Antworten aus der qualitativen Forschung basieren.

Wir haben uns für 2 Teilnehmende entschieden, die in unserem Studiengang sind und somit möglicherweise entsprechende Erfahrungen zu KI haben. Alle Teilnehmenden sind unmittelbar durch Gespräche auf dem Universitätsgelände rekrutiert worden. Dabei haben wir das eine Interview persönlich und das andere online über Discord. Das persönliche Interview wurde mit einem Smartphonemikrofon und das Online-Interview durch die Software OBS aufgenommen. Zur Transkiption haben wir Better-Whisper in einem lokalen Verzeichnis verwendet.

Für die Analyse haben wir uns für die Bottom-Up-Methode entschieden. Somit haben wir gemeinsam als Gruppe beide Transkriptionen gesichtet und jede Antwort separat, deduktiv kodiert und fortführend alle Codes zusammengefasst und entsprechende große Themen entwickelt. Wir haben keine besondere Software zur Analyse verwendet.

### Quantitative Methode

#### Ablauf der Datenerhebung

Für unsere quantitative Erhebung begann die Datenerhebung am Samstag, den 31.05.2025, und endete am Montag, den 10.06.2025. Zur Teilnahme an der Erhebung wurde den Probanden ein Link zur Verfügung gestellt, über den sie eigenständig teilnehmen konnten. Wir entschieden uns für ein Mixed Design, also eine Kombination aus einem Between-Subjects-Design und einem Within-Subjects-Design (@fig-ablaufdiagramm). Zur Untersuchung des Effekts von KI als Unterstützung bei der Detektion von Missinformationen sollten die Teilnehmenden zunächst Beiträge ohne KI bewerten und anschließend mit KI (Within-Subjects-Design). Um außerdem Unterschiede zwischen evaluativer und empfehlender KI in Bezug auf Workload, Genauigkeit etc. festzustellen, wurden die Teilnehmenden im zweiten Teil zufällig einer der beiden KI-Varianten zugeordnet. Jeweils die Hälfte der Antworten bezieht sich auf eine der beiden KI-Varianten (@fig-ablaufdiagramm).

#### Beschreibung der Teilnehmenden

Zum Abschluss unserer Erhebung haben 17 Teilnehmende unsere Studie vollständig abgeschlossen. Primär haben wir die Erhebung mit Studierenden und Personen im Alter zwischen 18 und 30 Jahren geteilt. Diese Zielgruppe wählten wir bewusst aus, da sie häufig viel Zeit auf sozialen Medien verbringen und im Rahmen von Studium oder Arbeit regelmäßig mit Recherche konfrontiert sind. Dadurch sind sie besonders häufig Missinformationen ausgesetzt. Dies führt dazu, dass sie ein aktuelleres Problembewusstsein im Umgang mit Missinformationen haben, was eine erhöhte Motivation zur Nutzung des Systems sowie ein besseres Verständnis für Risiken und Relevanz begünstigt. Ihre Anforderungen sind somit besonders aussagekräftig für die Gestaltung zukünftiger Systeme.

Gleichzeitig haben viele Teilnehmende bereits privat oder beruflich Erfahrungen mit KI-Tools gesammelt, wodurch ihre Nutzung und Bewertung des KI-Systems in unserer Erhebung realitätsnäher und reflektierter ausfallen könnte.

Um jedoch auch mögliche Unterschiede in den Ergebnissen zwischen verschiedenen Altersgruppen feststellen zu können, waren wir bemüht, zusätzlich Teilnehmende außerhalb des oben genannten Altersspektrums zu rekrutieren.

Ausschlusskriterien für Teilnehmer unserer Erhebung waren, dass sie minderjährig sind und aktuell die Veranstalltung SMNF besuchen.

#### Beschreibung der gewählten Erhebungsmethode

Wir haben wir uns bei der Erhebungsmethode für eine quantitative Methode entschieden. Hierzu wurden im Pre-Test-, Post-Baseline- und Post-Test-Fragebogen Skalen verwendet. Bei der Klassifizierung der Posts wurden je Post messbare Variablen sowie die Entscheidungssicherheit des Nutzers über eine Skala aufgenommen. Unter anderem wird die Technik-Affinität mittels einer ATI-Skala gemessen, das Informationsbewusstsein mithilfe einer SIPA-Skala und die Usability durch eine System Usability Scale.

#### Geplante Analysen

Mittels eines t-Tests soll untersucht werden, inwiefern der Einsatz von KI-Systemen die Entscheidungssicherheit bei der Bewertung von Misinformationen beeinflusst. Als abhängige Variable für den t-Test ist somit die Entscheidungssicherheit, die im Rahmen der Post-Klassifizierung ordinal auf einer sechsstufigen Skala erfasst wird. Verglichen werden die Mittelwerte der Baseline-Gruppe (ohne KI-Unterstützung) mit jenen der KI-Empfehlungsgruppe. Wir erwarten hierbei, dass die KI die Entscheidungssicherheit insgesamt erhöht, weshalb ein gerichteter t-Test geplant ist.
Wir halten die Analyse für relevant, da die Entscheidungssicherheit der Nutzenden bei der Beurteilung von Misinformationen wesentlich zu Akzeptanz und Effektivität von KI-Systemen beiträgt.

Des Weiteren soll bestimmt werden, ob eine Korrelation zwischen der Vorerfahrung mit KI seitens der Nutzenden mit der Bearbeitungszeit bei der Entscheidung besteht. Die zu untersuchenden Variablen sind hierbei „Vorwissen KI“, das im Rahmen des Pre-Test-Fragebogens auf einer Skala von 1-5 erfasst wird, sowie die in Sekunden bzw. Millisekunden gemessene „Bearbeitungszeit“ aus der Post-Klassifizierung.
Unsere Vermutung hierzu ist, dass Teilnehmende die eine größere Vorerfahrung mit KI angeben, eine geringere Bearbeitungszeit benötigen. Dies würde einer negativen Korrelation entsprechen.
Von den Ergebnissen dieser Analyse erhoffen wir uns Erkenntnisse über die Auswirkungen bestehender bzw. fehlender Vorerfahrungen mit KI im Zuge der effizienten Nutzung von KI-gestützten Entscheidungssystemen.

::: {#fig-ablaufdiagramm .figure .quarto-figure}
```{mermaid}
%%| fig-responsive: true
%%| fig-width: 6.5
%%| label: Ablaufdiagramm
%%| fig-cap: Ablaufdiagramm der quantitativen Studie
flowchart LR
 subgraph BASELINE["Phase 1: Ohne KI"]
    direction TB
        n4["Post-Baseline-Fragebogen"]
        n3["Baseline Klassifizierung ohne KI"]
  end
 subgraph KI_PHASE["Phase 2: Mit evaluativer KI"]
    direction TB
        n5["Klassifizierung mit KI"]
        n6["Post-Test-Fragebogen"]
  end
 subgraph KI_PHASE2["Phase 2: Mit empfehlender KI"]
    direction TB
        n12["Klassifizierung mit KI"]
        n13["Post-Test-Fragebogen <br>"]
  end
    n11["Start"] --> n1["Probandeninformationen"]
    n1 --> n2["Pre-Test-Fragebogen"]
    n2 --> n3
    n3 --> n4
    n5 --> n6
    n6 --> n7["Verabschiedung & Dank"]
    n7 --> n8["VP-Stunden-Umfrage"]
    n8 --> n9["Ende"]
    n12 --> n13
    n13 --> n7
    n4 --> n14["Randomization"]
    n14 --> n5
    n14 --> n12

    style n3 color:#000000
    style n5 color:#000000
    style n6 color:#000000
    style n12 color:#000000
    style n13 color:#000000
    style n11 color:#000000
    style n1 color:#000000
    style n2 color:#000000
    style n7 color:#000000
    style n8 color:#000000
    style n9 color:#000000
    style n14 color:#000000
    style KI_PHASE2 fill:transparent
    style KI_PHASE fill:transparent
    style BASELINE fill:transparent
```
:::

## 4. Ergebnisse

### Qualitative Ergebnisse

Bei unserer qualitativen Erhebung haben wir zwei Interviews geführt und gemeinsame analysiert. Besonders relevant bei unserer Stichprobe ist, dass beide Interviewpartner in einem jungen Alter sind, dementsprechend regelmäßig Social-Media nutzen und somit schon häufig in Kontakt mit Misinformationen waren.

Im Zuge der Analyse konnten wir einige Themen herausarbeiten, die im Folgenden erläutert werden sollen.

Zunächst ergibt sich die grundsätzliche Frage nach der Verantwortlichkeit und Regulierung für und von einer entsprechenden Anwendung. Dabei soll festgestellt werden, wo die Befragten die Zuständigkeit für das Betreiben, Instandhalten und die Qualitätsprüfung der Anwendung verorten (z.B. Staatliche Behörden, Social-Media-Plattformen,...). Beispiel: "Aber für die für die Implementation und für die Umsetzung sollten dann halt die Betreiber der verschiedenen Webseiten dann selbstverantwortlich sein." (B2_1, Zeile 134-136). @tbl-qualitative

Des Weiteren beschreibt das Thema "Darstellung und Abruf" die Anforderungen seitens der Befragten an die Kennzeichnung von Misinformation, bspw. durch die Verwendung entsprechender Symbole oder Farben. Hierbei soll auch die richtige Balance bei der Präsenz und Prägnanz der Darstellung gefunden werden: "Ich finde es sollte nicht aufdringlich sein, dementsprechend auch abschaltbar und es sollte sowohl optische als auch sozusagen faktisch nachprüfbare Anteile haben." (B2_2, Zeile 52-54). @tbl-qualitative

Außerdem ist die Transparenz und Quellenangabe seitens der KI bei ihrer Entscheidungsfindung von Relevanz. Ziel hiervon ist es, den Nutzenden das Nachvollziehen der Beurteilung von Informationen mithilfe entsprechender Begründungen und Angaben von Quellen zu ermöglichen: "Also ich würde mir das so vorstellen, dass wenn es zu einer Entscheidung kommt oder zu einer Einschätzung kommt, dass es dann auch dementsprechend Quellenangaben machen kann. Also dass man dann ganz klar sieht, ok, warum hat es sich jetzt dafür entschieden und wie ist es zu diesem Schluss gekommen." (B2_1, Zeile 142-146). @tbl-qualitative

| Thema | Definition | Textstelle |
|------------------------|------------------------|------------------------|
| Verantwortlichkeit und Regulierung | Die Frage nach der Verantwortlichkeit für Betreiben und Regulieren eines solchen KI-Systems (bspw. Plattformbetreiber, Staat oder Aufsichtsbehörden), insbesondere in Fällen von Versagen. | "Aber für die für die Implementation und für die Umsetzung sollten dann halt die Betreiber der verschiedenen Webseiten dann selbstverantwortlich sein." (B2_1, Zeile 134-136) |
| Darstellung und Abruf | Die Anforderungen an die Kennzeichnung von Misinformation, z. B. durch Farbcodes oder kleine Symbole, sowie eine nicht-aufdringliche Integration der KI in die Plattform. | "Ich finde es sollte nicht aufdringlich sein, dementsprechend auch abschaltbar und es sollte sowohl optische als auch sozusagen faktisch nachprüfbare Anteile haben." (B2_2, Zeile 52-54) |
| Transparenz und Quellenangabe | Die Anforderungen an die Nachvollziehbarkeit von KI-Entscheidungen, etwa durch transparente Quellenangaben, eine klare Darstellung des Prüfprozesses und die Offenlegung der Bewertungsgrundlagen. | "Also ich würde mir das so vorstellen, dass wenn es zu einer Entscheidung kommt oder zu einer Einschätzung kommt, dass es dann auch dementsprechend Quellenangaben machen kann. Also dass man dann ganz klar sieht, ok, warum hat es sich jetzt dafür entschieden und wie ist es zu diesem Schluss gekommen." (B2_1, Zeile 142-146) |

: Themen {#tbl-qualitative}

## 5. Diskussion

## Literaturverzeichnis

::: {#refs}
:::

### Anhang 1 - Rekrutierungstext

Jeden Tag werden unzählbar viele Inhalte auf Social Media veröffentlicht. Jeder kann selbst zum Autor werden und nicht immer ist klar, welche Information tatsächlich wahr ist. So entstehen schnell Missinformationen.\
Um dieses Problem weiter zu untersuchen, möchten wir mit unserer Studie herausfinden, ob eine künstliche Intelligenz dabei helfen kann, Missinformationen zu identifzieren und entsprechend zu kennzeichnen. Du sollst hierbei einmal ohne und einmal mit Empfehlung der KI entscheiden, ob ein Post Missinformation darstellt oder nicht.

Voraussetzungen

-   Mindestens 18 Jahre alt

-   Gute Deutschkenntnisse

-   Zugang zu PC oder Tablet (keine Smartphone-Teilnahme)

-   60 Minuten Zeit

-   Aktuell keine Teilnahme am Modul SMNF

Teilnahmelink:

Link öffnen (Bitte im Browser auf einem PC oder Tablet öffnen.)

VP-Stunden:

Studierende der Medieninformatik oder Psychologie an der Universität zu Lübeck können für die Teilnahme 1 VP-Stunde erhalten.
