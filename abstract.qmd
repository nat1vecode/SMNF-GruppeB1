---
title: "(Platzhalter)"
author: 
  - Fynn Luyken
  - Jorin Bahns
  - David Piekarski
  - Johannes Rehrl
  - Nathaniel Roumiantsev
date: today
format:
  html:
    toc: true
    number-sections: false
  pdf:
    papersize: a4
    fontsize: 12pt
    toc: true
    number-sections: false
bibliography: Literatur.bib
csl: apa.csl

output-file: abstract
---

**GitHub Repository** https://github.com/nat1vecode/SMNF-GruppeB1

**Für die Abgabe aktueller GitHub Hash:** 69smnf420...

## Code of Conduct

Im Rahmen dieser wissenschaftlichen Arbeit verpflichten sich alle beteiligten Personen zur Einhaltung folgender Verhaltensgrundsätze:

**Wissenschaftliche Integrität**

Alle Forschenden verpflichten sich zur Einhaltung guter wissenschaftlicher Praxis, insbesondere zur Ehrlichkeit in der Darstellung von Daten, Ergebnissen und Methoden. Plagiate, Datenfälschung und -manipulation werden strikt abgelehnt.

**Respektvolle Zusammenarbeit**

Die Zusammenarbeit im Team basiert auf gegenseitigem Respekt, Fairness und Gleichberechtigung. Diskriminierung, Belästigung oder andere Formen unangemessenen Verhaltens werden nicht toleriert. Vereinbarte und verpflichtende Termine werden zuverlässig eingehalten oder frühzeitig und begründet kommuniziert.

**Faire Aufteilung der Arbeitslast**

Jegliche Arbeit wird gleichmäßig auf alle Gruppenmitglieder aufgeteilt. Sollte sich jemand benachteiligt fühlen, kann dieser dies jederzeit kommunizieren und wird entsprechend berücksichtigt.

**Vermeidung von Interessenkonflikten & Berücksichtigung von Feedback**

Potenzielle Interessenkonflikte werden frühzeitig offengelegt und transparent kommuniziert, um die Unabhängigkeit und Objektivität der Forschung zu gewährleisten. Konstruktives Feedback wird jederzeit mit Wertschätzung aufgenommen, geprüft und entsprechend umgesetzt.

**Vertraulichkeit**

Vertrauliche Informationen, insbesondere personenbezogene Daten oder nicht veröffentlichte Forschungsergebnisse, werden mit der gebotenen Sorgfalt behandelt. Weiterhin verpflichten sich alle Gruppenmitglieder dazu, sämtliche im Zuge des Moduls SMNF (PY1802) erhobenen vertraulichen Daten nicht außerhalb des Moduls zu verbreiten.

**Umgang mit Künstlicher Intelligenz (KI)**

Künstliche Intelligenz darf zur Unterstützung bei Recherche, Analyse oder Textentwurf eingesetzt werden, muss jedoch in angemessener Form kenntlich gemacht werden. KI-Tools werden nicht als Quelle zitiert oder verwendet, sondern dienen ausschließlich der Hilfestellung im Arbeitsprozess.

## 1. Einleitung

Hallo!

## 2. Literaturübersicht

Des Weiteren erkennt das Paper "Cognitive AI for Mitigation of Misinformation in Online Social Networks" [@indu2022] die Relevanz menschlicher Kognitionspsychologie für die Analyse von (Mis-)Informationen, und fokussiert sich auf die Kombination dessen mit Künstlicher Intelligenz. Dabei wird darauf abgezielt, den Menschen bei der Beurteilung von Informationen in den sozialen Netzwerken zu unterstützen.

Das Paper „Zero-trust management using AI: Untrusting the trusted accounts in social media?“ [@fottouh2023] hebt hervor, dass das bloße Vertrauen in verifizierte Accounts nicht ausreicht, um die Qualität und Vertrauenswürdigkeit von Informationen auf Social Media sicherzustellen. Die Autoren regen dazu an, über die reine Identifikation von Fake-Accounts hinauszugehen und auch die Inhalte verifizierter Accounts zu analysieren. Im Hinblick auf unsere Forschungsfrage beschäftigt sich diese Arbeit mit der Notwendigkeit einer KI, welche nicht nur visuelle Merkmale (wie Verifizierung) berücksichtigt, sondern auch Informationen inhaltlich auf ihre Vertrauenswürdigkeit bewertet.

Das Paper „Using a Chatbot to Combat Misinformation: Exploring Gratifications, Chatbot Satisfaction and Engagement, and Relationship Quality Using a Chatbot to Combat Misinformation: Exploring Gratifications, Chatbot Satisfaction and Engagement, and Relationship Quality“ [@cheng2024] untersucht auf Basis der Uses-and-Gratifications-Theorie, die Nutzung des von der Weltgesundheitsorganisation (WHO) entwickelten Chatbots „Florence“, welcher entwickelt wurde um Informationen zu COVID-19 zu verbreiten. Bei einer Umfrage mit 591 Teilnehmern konnten Erkenntnisse gesammelt werden, das unter anderem technische Modernität (Modality), persönliche Unterstützung (Agency), Interaktivität (Interaction) und einfache Navigation (Navigability) die Nutzerzufriedenheit positiv beeinflussen. Im Gegenzug hemmen durch den Nutzer wahrgenommene Datenschutzrisiken die Zufriedenheit. Die Studie liefert dahingehend wertvolle Implikationen für die Gestaltung eines Chatbots, zur Bekämpfung von Fehlinformationen auf Sozialen Netzwerken.

Abschließend zeigt die Studie „Exploring the Use of Personalized AI for Identifying Misinformation on Social Media“ [@jahanbakhsh2023], wie personalisierte KI-Systeme die individuellen Einschätzungen der Nutzenden lernen und darauf basierend weitere Inhalte vorbewerten können. Interessant ist dabei die Erkenntnis, dass solche Systeme die Nutzermeinung beeinflussen können – besonders dann, wenn keine Begründung für die KI-Vorhersage gegeben wird. Das zeigt vor allem, dass KI ein zentrales Nutzendenbedürfnis darstellt: Nur wenn die Funktionsweise nachvollziehbar bleibt, kann eine nachhaltige Vertrauensbeziehung zwischen Nutzenden und System entstehen.

## 3. Methode

### Qualitative Methode

Unser Forschungsprojekt behandelt ein komplexes Themengebiet, das vor allem eine große soziale Komponente beeinhaltet. Mithilfe der qualitativen Methode können wir herausfinden, welche Erfahrungen Menschen mit KI gemacht haben und wie sie darüber denken. Insbesondere für die Nutzendenanforderungen ist es hilfreich, konkrete Vorstellungen zur Umsetzung einer KI zur Detektion von Misinformationen genannt zu bekommen.

Ergänzend hierzu bietet es sich nun an, quantitative Ansätze zur weiteren Forschung zu verwenden, die auf den Antworten aus der qualitativen Forschung basieren.

## 4. Ergebnisse

### Qualitative Ergebnisse

Bei unserer qualitativen Erhebung haben wir zwei Interviews geführt und gemeinsame analysiert. Besonders relevant bei unserer Stichprobe ist, dass beide Interviewpartner in einem jungen Alter sind, dementsprechend regelmäßig Social-Media nutzen und somit schon häufig in Kontakt mit Misinformationen waren.

Im Zuge der Analyse konnten wir einige Themen herausarbeiten, die im Folgenden erläutert werden sollen.

Zunächst ergibt sich die grundsätzliche Frage nach der Verantwortlichkeit und Regulierung für und von einer entsprechenden Anwendung. Dabei soll festgestellt werden, wo die Befragten die Zuständigkeit für das Betreiben, Instandhalten und die Qualitätsprüfung der Anwendung verorten (z.B. Staatliche Behörden, Social-Media-Plattformen,...).

Des Weiteren beschreibt das Thema "Darstellung und Abruf" die Anforderungen seitens der Befragten an die Kennzeichnung von Misinformation, bspw. durch die Verwendung entsprechender Symbole oder Farben. Hierbei soll auch die richtige Balance bei der Präsenz und Prägnanz der Darstellung gefunden werden: "Ich finde es sollte nicht aufdringlich sein, dementsprechend auch abschaltbar und es sollte sowohl optische als auch sozusagen faktisch nachprüfbare Anteile haben." (TP_2, Zeile 52-54).

Außerdem ist die Transparenz und Quellenangabe seitens der KI bei ihrer Entscheidungsfindung von Relevanz. Ziel hiervon ist es, den Nutzenden das Nachvollziehen der Beurteilung von Informationen mithilfe entsprechender Begründungen und Angaben von Quellen zu ermöglichen: "Also ich würde mir das so vorstellen, dass wenn es zu einer Entscheidung kommt oder zu einer Einschätzung kommt, dass es dann auch dementsprechend Quellenangaben machen kann. Also dass man dann ganz klar sieht, ok, warum hat es sich jetzt dafür entschieden und wie ist es zu diesem Schluss gekommen." (B2_1, Zeile 142-146).

| Thema | Definition | Textstelle |
|----|----|----|
| Verantwortlichkeit und Regulierung | Die Frage nach der Verantwortlichkeit für Betreiben und Regulieren eines solchen KI-Systems (bspw. Plattformbetreiber, Staat oder Aufsichtsbehörden), insbesondere in Fällen von Versagen. | "Aber für die für die Implementation und für die Umsetzung sollten dann halt die Betreiber der verschiedenen Webseiten dann selbstverantwortlich sein." (B2_1, Zeile 134-136) |
| Darstellung und Abruf | Die Anforderungen an die Kennzeichnung von Misinformation, z. B. durch Farbcodes oder kleine Symbole, sowie eine nicht-aufdringliche Integration der KI in die Plattform. | "Ich finde es sollte nicht aufdringlich sein, dementsprechend auch abschaltbar und es sollte sowohl optische als auch sozusagen faktisch nachprüfbare Anteile haben." (TP_2, Zeile 52-54) |
| Transparenz und Quellenangabe | Die Anforderungen an die Nachvollziehbarkeit von KI-Entscheidungen, etwa durch transparente Quellenangaben, eine klare Darstellung des Prüfprozesses und die Offenlegung der Bewertungsgrundlagen. | "Also ich würde mir das so vorstellen, dass wenn es zu einer Entscheidung kommt oder zu einer Einschätzung kommt, dass es dann auch dementsprechend Quellenangaben machen kann. Also dass man dann ganz klar sieht, ok, warum hat es sich jetzt dafür entschieden und wie ist es zu diesem Schluss gekommen." (B2_1, Zeile 142-146) |

## 5. Diskussion

## Literaturverzeichnis
