@INPROCEEDINGS{jahanbakhsh2023,
author = {Jahanbakhsh, Farnaz and Katsis, Yannis and Wang, Dakuo and Popa, Lucian and Muller, Michael},
title = {Exploring the Use of Personalized AI for Identifying Misinformation on Social Media},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581219},
doi = {10.1145/3544548.3581219},
abstract = {This work aims to explore how human assessments and AI predictions can be combined to identify misinformation on social media. To do so, we design a personalized AI which iteratively takes as training data a single user’s assessment of content and predicts how the same user would assess other content. We conduct a user study in which participants interact with a personalized AI that learns their assessments of a feed of tweets, shows its predictions of whether a user would find other tweets (in)accurate, and evolves according to the user feedback. We study how users perceive such an AI, and whether the AI predictions influence users’ judgment. We find that this influence does exist and it grows larger over time, but it is reduced when users provide reasoning for their assessment. We draw from our empirical observations to identify design implications and directions for future work.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {105},
numpages = {27},
keywords = {Artificial Intelligence, Democratized Content Moderation, Fact Checking, Misinformation, Social Media},
location = {Hamburg, Germany},
series = {CHI '23}
}

@INPROCEEDINGS {fottouh2023,
author = { Fottouh, Nihad and Moussa, Sherin M. },
booktitle = { 2023 20th ACS/IEEE International Conference on Computer Systems and Applications (AICCSA) },
title = {{ Zero-trust management using AI: Untrusting the trusted accounts in social media }},
year = {2023},
volume = {},
ISSN = {},
pages = {1-7},
abstract = { Can we trust verified accounts on social media? With the recent exponential inflation of social media in every aspect, tremendous efforts have been directed to comprehend, analyze, relate, predict, secure, privacy-preserve, and validate its content. This included natural language processing, sentiment analysis, opinion mining, fake accounts/news detection, graph mining, recommendations, anonymization, …, etc. However, assessing the trust level of the disseminated content was never addressed. Social media users are left to deal with the content of the verified accounts and decide for themselves whether they are true or fake. This raises a dire concern: how can we evaluate the trust level of the content posed by the verified accounts we follow? In this paper, we investigate the challenges of zero-trust management for content in social media. We draw the community’s attention to go beyond fake accounts/content detection and explore trust assessment of content for the legitimate account, rather than solely checking whether it is verified or not. In this regard, we derive a set of open challenges with AI-based solutions for further investigation to maintain a trustworthy social media ecosystem with trusted content. },
keywords = {Sentiment analysis;Data privacy;Social networking (online);Ecosystems;Zero Trust;Information filtering;Reliability},
doi = {10.1109/AICCSA59173.2023.10479254},
url = {https://doi.ieeecomputersociety.org/10.1109/AICCSA59173.2023.10479254},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month =Dec}