@INPROCEEDINGS{jahanbakhsh2023,
author = {Jahanbakhsh, Farnaz and Katsis, Yannis and Wang, Dakuo and Popa, Lucian and Muller, Michael},
title = {Exploring the Use of Personalized AI for Identifying Misinformation on Social Media},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581219},
doi = {10.1145/3544548.3581219},
abstract = {This work aims to explore how human assessments and AI predictions can be combined to identify misinformation on social media. To do so, we design a personalized AI which iteratively takes as training data a single user’s assessment of content and predicts how the same user would assess other content. We conduct a user study in which participants interact with a personalized AI that learns their assessments of a feed of tweets, shows its predictions of whether a user would find other tweets (in)accurate, and evolves according to the user feedback. We study how users perceive such an AI, and whether the AI predictions influence users’ judgment. We find that this influence does exist and it grows larger over time, but it is reduced when users provide reasoning for their assessment. We draw from our empirical observations to identify design implications and directions for future work.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {105},
numpages = {27},
keywords = {Artificial Intelligence, Democratized Content Moderation, Fact Checking, Misinformation, Social Media},
location = {Hamburg, Germany},
series = {CHI '23}
}

@INPROCEEDINGS {fottouh2023,
author = { Fottouh, Nihad and Moussa, Sherin M. },
booktitle = { 2023 20th ACS/IEEE International Conference on Computer Systems and Applications (AICCSA) },
title = {{ Zero-trust management using AI: Untrusting the trusted accounts in social media }},
year = {2023},
volume = {},
ISSN = {},
pages = {1-7},
abstract = { Can we trust verified accounts on social media? With the recent exponential inflation of social media in every aspect, tremendous efforts have been directed to comprehend, analyze, relate, predict, secure, privacy-preserve, and validate its content. This included natural language processing, sentiment analysis, opinion mining, fake accounts/news detection, graph mining, recommendations, anonymization, …, etc. However, assessing the trust level of the disseminated content was never addressed. Social media users are left to deal with the content of the verified accounts and decide for themselves whether they are true or fake. This raises a dire concern: how can we evaluate the trust level of the content posed by the verified accounts we follow? In this paper, we investigate the challenges of zero-trust management for content in social media. We draw the community’s attention to go beyond fake accounts/content detection and explore trust assessment of content for the legitimate account, rather than solely checking whether it is verified or not. In this regard, we derive a set of open challenges with AI-based solutions for further investigation to maintain a trustworthy social media ecosystem with trusted content. },
keywords = {Sentiment analysis;Data privacy;Social networking (online);Ecosystems;Zero Trust;Information filtering;Reliability},
doi = {10.1109/AICCSA59173.2023.10479254},
url = {https://doi.ieeecomputersociety.org/10.1109/AICCSA59173.2023.10479254},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month =Dec}

@ARTICLE{indu2022,
author={V, Indu and Thampi, Sabu M.},
journal={ IT Professional },
title={{ Cognitive AI for Mitigation of Misinformation in Online Social Networks }},
year={2022},
volume={24},
number={05},
ISSN={1941-045X},
pages={37-45},
abstract={ Misinformation propagation in social networks has emerged as a crucial problem that needs to be attended with prime importance. Despite the existence of several fact-checking mechanisms and misinformation detection tools, users of social media platforms continue to be the victims of misinformation propagation. This is because human cognition is a strong factor that drives users in consuming and spreading misinformation. This article highlights the significance of cognitive psychology in misinformation propagation analysis and summarizes the challenges faced by current misinformation detection mechanisms. The study shows that there is an immediate requirement for efficient mechanisms combining AI and cognitive psychology that can support humans in making judgements regarding the information appearing on social networks. A cognitive AI framework is proposed that can augment humans’ capability in assessing the veracity of the information online and reinforce positive information sharing behavior in individuals thereby reducing the spread of misinformation. },
keywords={Social networking (online);Psychology;Information sharing;Feature extraction;Cognition;Fake news;Artificial intelligence},
doi={10.1109/MITP.2022.3168790},
url = {https://doi.ieeecomputersociety.org/10.1109/MITP.2022.3168790},
publisher={IEEE Computer Society},
address={Los Alamitos, CA, USA},
month=sep}
